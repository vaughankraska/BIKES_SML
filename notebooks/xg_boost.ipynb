{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import cpu_count\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, RandomizedSearchCV\n",
    "from src.utils import load_data, initialize_model_pipeline, cross_validate_model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from os import cpu_count"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T20:29:03.358505800Z",
     "start_time": "2023-12-06T20:29:03.350994Z"
    }
   },
   "id": "c4743eee41412592"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/thea.csv')\n",
    "X = data.drop('increase_stock', axis=1)\n",
    "Y = data['increase_stock']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T20:29:03.763172500Z",
     "start_time": "2023-12-06T20:29:03.753532Z"
    }
   },
   "id": "2493fd476b0b4f19"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "2/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "3/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "4/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "5/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "6/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "7/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "8/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "9/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "10/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "11/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "12/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "13/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "14/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "15/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "16/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "17/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "18/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "19/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "20/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "21/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "22/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "23/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "24/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "25/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "26/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "27/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "28/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "29/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "30/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "31/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "32/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "33/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "34/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "35/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "36/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "37/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "38/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "39/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "40/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "41/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "42/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "43/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "44/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "45/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "46/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "47/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "48/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "49/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "50/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "51/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "52/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "53/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "54/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "55/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "56/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "57/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "58/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "59/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "60/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "61/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "62/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "63/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "64/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "65/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "66/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "67/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "68/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "69/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "70/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "71/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "72/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "73/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "74/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "75/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "76/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "77/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "78/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "79/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "80/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "81/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "82/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "83/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "84/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "85/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "86/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "87/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "88/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "89/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "90/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "91/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "92/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "93/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "94/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "95/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "96/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "97/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "98/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "99/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n",
      "100/100\n",
      "Fitting 150 folds for each of 18 candidates, totalling 2700 fits\n"
     ]
    }
   ],
   "source": [
    "bs_results = []\n",
    "#only optimize n_estimators, max depth, colsample_bytree\n",
    "param_grid = {\n",
    "    'learning_rate': [0.05, .1, .15],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [4, 5],\n",
    "    'subsample': [.75],\n",
    "    'colsample_bytree': [0.75],\n",
    "    'gamma': [0],\n",
    "    'min_child_weight': [3],\n",
    "    'reg_lambda': [0.1]\n",
    "}\n",
    "\n",
    "for i in range(100):\n",
    "    print(f'{i + 1}/100')\n",
    "    result = {}\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                        test_size=1 / 16,  #save 100 holdout\n",
    "                                                        random_state=i + 1)\n",
    "    kf = KFold(n_splits=150, shuffle=True) #150 so that we have 10 samples tested on each fold\n",
    "    m = XGBClassifier()\n",
    "    search = GridSearchCV(m,\n",
    "                          param_grid=param_grid,\n",
    "                          cv=kf,\n",
    "                          scoring='accuracy',\n",
    "                          n_jobs=cpu_count() - 1,\n",
    "                          verbose=2)\n",
    "    search.fit(x_train, y=y_train)\n",
    "    result['accuracy'] = accuracy_score(y_test, search.best_estimator_.predict(x_test))\n",
    "    result['optimistic_accuracy'] = search.best_score_ \n",
    "    result['class_report'] = classification_report(y_test, search.best_estimator_.predict(x_test))\n",
    "    result['best_params'] = search.best_params_\n",
    "    result['model'] = search.best_estimator_\n",
    "    bs_results.append(result)\n",
    "\n",
    "bs_results = pd.DataFrame(bs_results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T20:50:15.442529Z",
     "start_time": "2023-12-06T20:29:04.343136900Z"
    }
   },
   "id": "a00225d9d0d22ab9"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "    accuracy  optimistic_accuracy  \\\n0       0.91             0.896667   \n1       0.86             0.902667   \n2       0.92             0.898667   \n3       0.93             0.898667   \n4       0.86             0.900000   \n..       ...                  ...   \n95      0.88             0.898000   \n96      0.90             0.895333   \n97      0.86             0.903333   \n98      0.90             0.898000   \n99      0.91             0.896667   \n\n                                         class_report  \\\n0                 precision    recall  f1-score   ...   \n1                 precision    recall  f1-score   ...   \n2                 precision    recall  f1-score   ...   \n3                 precision    recall  f1-score   ...   \n4                 precision    recall  f1-score   ...   \n..                                                ...   \n95                precision    recall  f1-score   ...   \n96                precision    recall  f1-score   ...   \n97                precision    recall  f1-score   ...   \n98                precision    recall  f1-score   ...   \n99                precision    recall  f1-score   ...   \n\n                                          best_params  \\\n0   {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n1   {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n2   {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n3   {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n4   {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n..                                                ...   \n95  {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n96  {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n97  {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n98  {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n99  {'colsample_bytree': 0.75, 'gamma': 0, 'learni...   \n\n                                                model  \n0   XGBClassifier(base_score=None, booster=None, c...  \n1   XGBClassifier(base_score=None, booster=None, c...  \n2   XGBClassifier(base_score=None, booster=None, c...  \n3   XGBClassifier(base_score=None, booster=None, c...  \n4   XGBClassifier(base_score=None, booster=None, c...  \n..                                                ...  \n95  XGBClassifier(base_score=None, booster=None, c...  \n96  XGBClassifier(base_score=None, booster=None, c...  \n97  XGBClassifier(base_score=None, booster=None, c...  \n98  XGBClassifier(base_score=None, booster=None, c...  \n99  XGBClassifier(base_score=None, booster=None, c...  \n\n[100 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accuracy</th>\n      <th>optimistic_accuracy</th>\n      <th>class_report</th>\n      <th>best_params</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.91</td>\n      <td>0.896667</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.86</td>\n      <td>0.902667</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.92</td>\n      <td>0.898667</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.93</td>\n      <td>0.898667</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.86</td>\n      <td>0.900000</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.88</td>\n      <td>0.898000</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.90</td>\n      <td>0.895333</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.86</td>\n      <td>0.903333</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.90</td>\n      <td>0.898000</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.91</td>\n      <td>0.896667</td>\n      <td>precision    recall  f1-score   ...</td>\n      <td>{'colsample_bytree': 0.75, 'gamma': 0, 'learni...</td>\n      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T20:51:04.652976700Z",
     "start_time": "2023-12-06T20:51:04.634743300Z"
    }
   },
   "id": "883a8ebd1ecf12a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we can look at the results of our *process* as a whole\n",
    "#### if the model was overfitting too much, we would expect the out of sample scores to be much less"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb828fd0cdb5c"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out of sample accuracy - optimistic accuracy = -0.0059866666666667945\n"
     ]
    },
    {
     "data": {
      "text/plain": "accuracy               0.892100\noptimistic_accuracy    0.898087\ndtype: float64"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'out of sample accuracy - optimistic accuracy = {np.mean(bs_results[\"accuracy\"] - bs_results[\"optimistic_accuracy\"])}')\n",
    "bs_results[['accuracy','optimistic_accuracy']].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T21:09:22.233193600Z",
     "start_time": "2023-12-06T21:09:22.203790800Z"
    }
   },
   "id": "2b9319305d05ddd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### solid evidence that our optimization process is selected such that it does *not* overfit the data\n",
    "##### Lets look at the confidence interval of our true estimate based on the XG boost process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d26249013aa0fc2"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~95% CI on out of sample accuracy [0.84, 0.93]\n"
     ]
    }
   ],
   "source": [
    "# noinspection PyArgumentList\n",
    "quantile_5 = np.percentile(bs_results['accuracy'], 5, interpolation=\"linear\")\n",
    "# noinspection PyArgumentList\n",
    "quantile_95 = np.percentile(bs_results['accuracy'], 95, interpolation=\"linear\")\n",
    "print(f'~95% CI on out of sample accuracy [{quantile_5}, {quantile_95}]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T21:18:06.775134300Z",
     "start_time": "2023-12-06T21:18:06.765404400Z"
    }
   },
   "id": "5b0dfe64e94ca753"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "# bs_results.to_pickle('../xg_boost_optimal_results.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T21:23:46.890246900Z",
     "start_time": "2023-12-06T21:23:46.721214500Z"
    }
   },
   "id": "bb5d3f28dc5ca9e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# best params grid (no alpha or lambda):\n",
    "# {'colsample_bytree': 1.0, 'gamma': 0.2, 'learning_rate': 0.05, 'max_depth': 5, 'max_iter': 10000, 'min_child_weight': 1, 'n_estimators': 100, 'scale_pos_weight': 1, 'subsample': 0.75}\n",
    "# best_score: 0.896875\n",
    "\n",
    "# best params :\n",
    "# {'colsample_bytree': 0.75, 'gamma': 0, 'learning_rate': 0.15, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 50, 'reg_lambda': 0.9, 'subsample': 1.0}\n",
    "# best_score: 0.905\n",
    "\n",
    "# best RANDOM params:\n",
    "# {'subsample': 0.5, 'scale_pos_weight': 1, 'reg_lambda': 0.9, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.2, 'colsample_bytree': 0.75}\n",
    "# best_score: 0.9018750000000001\n",
    "\n",
    "# best params:\n",
    "# {'colsample_bytree': 0.75, 'gamma': 0.3, 'learning_rate': 0.075, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 75, 'reg_lambda': 0.1, 'subsample': 0.75}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5ffb74e75bd4d56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "83ca39c2d83404cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
